{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте mapper первой mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.\n",
    "\n",
    "Формат входных данных следующий: каждая строка содержит номер документа и строку из него, разделенные \":\". Ключ выходных данных является составным: он содержит слово документа и его номер, разделенные \"#\". \n",
    "\n",
    "Слово в документе - последовательность символов (букв или цифр), не содержащая пробельных символов и знаков пунктуации.\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "    1:1abc:2abc:3abc\n",
    "    2:1bcd::2bcd::3bcd::\n",
    "    3:1cde:::2cde:::3cde:::\n",
    "    34:t0t1:g5_6:::::  :4=1\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "    1abc#1\t1\n",
    "    2abc#1\t1\n",
    "    3abc#1\t1\n",
    "    1bcd#2\t1\n",
    "    2bcd#2\t1\n",
    "    3bcd#2\t1\n",
    "    1cde#3\t1\n",
    "    2cde#3\t1\n",
    "    3cde#3\t1\n",
    "    t0t1#34\t1\n",
    "    g5#34\t1\n",
    "    6#34\t1\n",
    "    4#34\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1abc#1\t1\n",
      "2abc#1\t1\n",
      "3abc#1\t1\n",
      "1bcd#2\t1\n",
      "2bcd#2\t1\n",
      "3bcd#2\t1\n",
      "1cde#3\t1\n",
      "2cde#3\t1\n",
      "3cde#3\t1\n",
      "t0t1#34\t1\n",
      "g5_6#34\t1\n",
      "4#34\t1\n",
      "1#34\t1\n"
     ]
    }
   ],
   "source": [
    "with open('data/data13.txt', 'r') as f:\n",
    "    \n",
    "    import re\n",
    "\n",
    "\n",
    "    word_pattern = re.compile(r'\\w+')\n",
    "\n",
    "    for line in f:\n",
    "\n",
    "        key, value = line.strip().split(':', maxsplit=1)\n",
    "        for match in word_pattern.finditer(value):\n",
    "            print(f'{value[match.start():match.end()]}#{key}\\t1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте reducer первой mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.\n",
    "\n",
    "Ключ входных данных составной: он содержит слово и номер документа через \"#\".\n",
    "\n",
    "Ключом в выходных данных является слово, а значение состоит из двух элементов, разделенных табуляцией: номер документа и tf (сколько раз данное слово встретилось в данном документе).\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "    aut#1\t1\n",
    "    aut#1\t1\n",
    "    aut#1\t1\n",
    "    aut#1\t1\n",
    "    aut#2\t1\n",
    "    aut#2\t1\n",
    "    bene#2\t1\n",
    "    de#2\t1\n",
    "    mortuis#2\t1\n",
    "    nihil#1\t1\n",
    "    nihil#2\t1\n",
    "    Caesar#1\t1\n",
    "    \n",
    "Sample Output:\n",
    "\n",
    "    aut\t1\t4\n",
    "    aut\t2\t2\n",
    "    bene\t2\t1\n",
    "    de\t2\t1\n",
    "    mortuis\t2\t1\n",
    "    nihil\t1\t1\n",
    "    nihil\t2\t1\n",
    "    Caesar\t1\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aut\t1\t4\n",
      "aut\t2\t2\n",
      "bene\t2\t1\n",
      "de\t2\t1\n",
      "mortuis\t2\t1\n",
      "nihil\t1\t1\n",
      "nihil\t2\t1\n",
      "Caesar\t1\t1\n"
     ]
    }
   ],
   "source": [
    "with open('data/data14.txt', 'r') as f:\n",
    "    \n",
    "    last_key, _sum = None, 0\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        key, value = line.strip().split()\n",
    "        \n",
    "        if last_key and last_key != key:\n",
    "            term, id_doc = last_key.split('#')\n",
    "            print(f'{term}\\t{id_doc}\\t{_sum}')\n",
    "            last_key, _sum = key, 1\n",
    "        else:\n",
    "            last_key, _sum = key, _sum+1\n",
    "            \n",
    "    if last_key:\n",
    "        term, id_doc = last_key.split('#')\n",
    "        print(f'{term}\\t{id_doc}\\t{_sum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте mapper ﻿второй mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.\n",
    "\n",
    "Во входных данных ключом является слово, а значение состоит из номера документа и tf, разделенных табуляцией.\n",
    "\n",
    "Значение в выходных данных - это тройка: номер документа, tf и единица, разделенные \";\".\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "    aut\t1\t4\n",
    "    aut\t2\t2\n",
    "    bene\t2\t1\n",
    "    de\t2\t1\n",
    "    mortuis\t2\t1\n",
    "    nihil\t1\t1\n",
    "    nihil\t2\t1\n",
    "    Caesar\t1\t1\n",
    "    \n",
    "Sample Output:\n",
    "\n",
    "    aut\t1;4;1\n",
    "    aut\t2;2;1\n",
    "    bene\t2;1;1\n",
    "    de\t2;1;1\n",
    "    mortuis\t2;1;1\n",
    "    nihil\t1;1;1\n",
    "    nihil\t2;1;1\n",
    "    Caesar\t1;1;1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aut\t1;4;1\n",
      "aut\t2;2;1\n",
      "bene\t2;1;1\n",
      "de\t2;1;1\n",
      "mortuis\t2;1;1\n",
      "nihil\t1;1;1\n",
      "nihil\t2;1;1\n",
      "Caesar\t1;1;1\n"
     ]
    }
   ],
   "source": [
    "with open('data/data15.txt', 'r') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        term, id_doc, tf = line.strip().split()\n",
    "        print(f'{term}\\t{id_doc};{tf};1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте reducer второй mapreduce задачи для расчета TF-IDF с помощью Hadoop Streaming.\n",
    "\n",
    "Входные данные: ключ - слово, значение - тройка: номер документа, tf слова в документе и 1 (разделены ';').\n",
    "\n",
    "Выходные данные: ключ - пара: слово, номер документа (разделены '#'), значение - пара: tf слова в документе, n - количество документов с данным словом (разделены табуляцией).\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "    aut\t1;4;1\n",
    "    aut\t2;2;1\n",
    "    bene\t2;1;1\n",
    "    de\t2;1;1\n",
    "    mortuis\t2;1;1\n",
    "    nihil\t1;1;1\n",
    "    nihil\t2;1;1\n",
    "    Caesar\t1;1;1\n",
    "    \n",
    "Sample Output:\n",
    "\n",
    "    aut#1\t4\t2\n",
    "    aut#2\t2\t2\n",
    "    bene#2\t1\t1\n",
    "    de#2\t1\t1\n",
    "    mortuis#2\t1\t1\n",
    "    nihil#1\t1\t2\n",
    "    nihil#2\t1\t2\n",
    "    Caesar#1\t1\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aut#1\t4\t2\n",
      "aut#2\t2\t2\n",
      "bene#2\t1\t1\n",
      "de#2\t1\t1\n",
      "mortuis#2\t1\t1\n",
      "nihil#1\t1\t2\n",
      "nihil#2\t1\t2\n",
      "Caesar#1\t1\t1\n"
     ]
    }
   ],
   "source": [
    "with open('data/data16.txt', 'r') as f:\n",
    "    \n",
    "    lst = []\n",
    "    last_key = None\n",
    "\n",
    "    for line in f:\n",
    "        key, value = line.strip().split()\n",
    "        id_doc, tf, _ = value.split(';')\n",
    "\n",
    "        if last_key and last_key != key:\n",
    "            for i_key, i_id_doc, i_tf in lst:\n",
    "                print(f'{i_key}#{i_id_doc}\\t{i_tf}\\t{len(lst)}')\n",
    "            del lst[:]\n",
    "            lst.append((key, id_doc, tf))\n",
    "        else:\n",
    "            lst.append((key, id_doc, tf))\n",
    "\n",
    "        last_key = key\n",
    "\n",
    "    if last_key:\n",
    "        for i_key, i_id_doc, i_tf in lst:\n",
    "            print(f'{i_key}#{i_id_doc}\\t{i_tf}\\t{len(lst)}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
